# ğŸ¯ **TalentEdge Course Scraper**

![Python](https://img.shields.io/badge/Python-3.8%2B-blue?style=for-the-badge&logo=python)
![Scrapy](https://img.shields.io/badge/Scrapy-2.11.0-green?style=for-the-badge&logo=scrapy)
![Pandas](https://img.shields.io/badge/Pandas-1.5.3-orange?style=for-the-badge&logo=pandas)
![Excel](https://img.shields.io/badge/Excel-Data%20Export-brightgreen?style=for-the-badge&logo=microsoft-excel)

## ğŸš€ **Project Overview**
This project is a web scraper built using `Scrapy` to extract detailed course information from [TalentEdge](https://talentedge.com). The scraper navigates through course pages and collects data, including:
- **Course Title**
- **Description**
- **Duration, Timing & Start Date**
- **Skills & Learning Outcomes**
- **Eligibility Criteria**
- **Topics Covered**
- **Faculty Information (Names, Designations, Descriptions)**
- **Institute Name**
- **Course Fee in INR & USD**
- **Target Audience**

The extracted data is saved in a structured Excel file for easy reference and analysis. âœ…

---

## âš™ï¸ **Tech Stack**
- **Language:** Python 3.8+
- **Libraries:** 
  - `Scrapy` â†’ For web scraping  
  - `Pandas` â†’ For data manipulation and export  
  - `OpenPyXL` â†’ For Excel handling  
- **Data Format:** Excel (`.xlsx`)

---

## ğŸ“Š **Directory Structure**
```
ğŸ“ TalentEdge-Scraper  
 â”œâ”€â”€ ğŸ“„ README.md             â†’ Project documentation  
 â”œâ”€â”€ ğŸ“„ requirements.txt      â†’ List of dependencies  
 â”œâ”€â”€ ğŸ“„ course_data.xlsx      â†’ Output Excel file with scraped data  
 â”œâ”€â”€ ğŸ“„ scrapy.cfg            â†’ Scrapy configuration  
 â”œâ”€â”€ ğŸ“ spiders               â†’ Spider scripts  
 â”‚     â””â”€â”€ data_spider.py     â†’ Main scraper script  
 â”œâ”€â”€ ğŸ“ logs                  â†’ Logs for debugging  
 â””â”€â”€ ğŸ“ output                â†’ (Optional) Store raw HTML or JSON files
```

---

## ğŸ”§ **Installation**
1. **Clone the Repository**
```bash
git clone https://github.com/Nidhiii2/Web-Scraping-Project.git
cd TalentEdge-Scraper
```

2. **Create a Virtual Environment**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate      # Windows
```

3. **Install Dependencies**
```bash
pip install -r requirements.txt
```

---

## ğŸš¦ **Usage**
1. **Run the Scraper**
```bash
scrapy crawl data
```

2. **Output**
- The scraped data is saved in `course_data.xlsx`.
- The Excel file contains all the extracted course details in a tabular format.

---

## ğŸ”¥ **Features**
âœ”ï¸ Extracts comprehensive course details from multiple pages  
âœ”ï¸ Exports data into Excel format  
âœ”ï¸ Handles missing data gracefully  
âœ”ï¸ Supports dynamic crawling of multiple course URLs  

---

## ğŸ› ï¸ **Customization**
You can easily add more course URLs by modifying the `start_requests()` method:
```python
urls = [
    "https://talentedge.com/iim-kozhikode/professional-certificate-programme-in-hr-management-and-analytics",
    "https://talentedge.com/iim-lucknow/supply-chain-management",
    "https://talentedge.com/iim-raipur/certificate-course-machine-learning-for-managers",
]
```
Add or remove URLs as required. 

---

## âœ… **Example Output**

| Course Title                                   | Duration    | Start Date     | Faculty               | Fee in INR   | Fee in USD    |
|------------------------------------------------|-------------|----------------|------------------------|--------------|----------------|
| HR Management & Analytics                      | 12 months   | Aug 2025       | Dr. XYZ (IIM K)        | INR 1,00,000 | USD 1,200      |
| Machine Learning for Managers                   | 6 months    | Sep 2025       | Prof. ABC (IIM Raipur) | INR 80,000   | USD 1,000      |
| Doctor of Business Administration (GGU)         | 36 months   | Rolling Basis  | Dr. DEF (GGU)          | INR 3,50,000 | USD 4,200      |

---

## âš ï¸ **Error Handling & Logging**
- All errors are logged in the `logs/` folder.
- Graceful handling of missing or invalid data prevents script crashes.

---

## ğŸ“š **Dependencies**
Install the necessary libraries by running:
```bash
pip install scrapy pandas openpyxl
```

---

## ğŸ“Œ **Future Enhancements**
âœ… Add support for JSON/CSV exports  
âœ… Implement multi-threaded scraping for faster execution  
âœ… Include dynamic course pagination scraping  

---

## ğŸ‘©â€ğŸ’» **Author**
ğŸ‘‹ Developed by **Nidhi Saroj**  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/nidhi-saroj-705b362a6/) | [GitHub](https://github.com/Nidhiii2)
